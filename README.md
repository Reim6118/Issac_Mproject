# Research Objective
#### This project aims to create a system that can automatically generate haptic audio for a video based on events, the output haptic audio can then be directly use in manual authoring tools to improve efficiency of manual authoring task. While in this particular research, the system is only capable to automatic generate haptic feedbacks from scenario of  badminton matches. 

# System Overview

##### The system consist of two deep learning model (Object detection, Sound Event Detection) to seperately process the audio and visual content from a video. Both of data will be processed with machine learning models and algorithms to find the frame that have high possibility containing the event that can generate haptics, in this case, the frame when the racket and badminton contacts. After filtering out the frames that fulfil the requirement, the system will create a haptic audio based on those frame with the haptic sensation directily recorded from a real badminton racket.

<img width="574" alt="image" src="https://github.com/Reim6118/Issac_Mproject/assets/32570797/d1ef34a0-f65d-476d-a886-277db9954340">


<img width="1325" alt="Screenshot 2024-02-26 at 15 49 37" src="https://github.com/Reim6118/Issac_Mproject/assets/32570797/5e5235de-e85d-4f6d-a365-91701421af17">

<img width="1309" alt="Screenshot 2024-02-26 at 15 54 08" src="https://github.com/Reim6118/Issac_Mproject/assets/32570797/38fbd42e-a90f-4316-a7da-9ee305fab51a">


<img width="1309" alt="Screenshot" src="https://github.com/Reim6118/Issac_Mproject/assets/32570797/256116ac-4b8c-4e7d-bd9d-e68c38769855">

<img width="385" alt="image" src="https://github.com/Reim6118/Issac_Mproject/assets/32570797/7cd8dadf-b972-4086-a569-3d65e112995f">

<img width="385" alt="Screenshot2" src="https://github.com/Reim6118/Issac_Mproject/assets/32570797/e95251a8-a004-4779-b9c9-93060973b566">


<img width="523" alt="image" src="https://github.com/Reim6118/Issac_Mproject/assets/32570797/6b524ff8-4f3e-4020-950e-d993604e6538">

